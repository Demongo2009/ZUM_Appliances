#data$logT5=log(data$T5)
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
data$logT4=log(data$T4)
#data$logT5=log(data$T5)
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
data$logVisibility = log(data$Visibility)
data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
data$logT9=log(data$T9)
data$logT3=log(data$T3)
data$logT4=log(data$T4)
data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
#data$logVisibility = log(data$Visibility)
#data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
atributes <- data[,!names(data) %in% c("date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances")]
str(atributes)
atributes_with_interactions = model.matrix(~(lights+Press_mm_hg+RH_1+RH_2+RH_6+RH_7+RH_8+RH_9+RH_out+T_out+T1+T2+T6+T7+T8+hour+time_of_day+logT9+logT3+logT4+logT5)^2,atributes)
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
#data$logVisibility = log(data$Visibility)
#data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
atributes <- data[,!names(data) %in% c("date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances")]
str(atributes)
atributes_with_interactions = model.matrix(~(lights+Press_mm_hg+RH_1+RH_2+RH_6+RH_7+RH_8+RH_9+RH_out+T_out+T1+T2+T6+T7+T8+hour+time_of_day+)^2,atributes)
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
#data$logVisibility = log(data$Visibility)
#data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
atributes <- data[,!names(data) %in% c("date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances")]
str(atributes)
atributes_with_interactions = model.matrix(~(lights+Press_mm_hg+RH_1+RH_2+RH_6+RH_7+RH_8+RH_9+RH_out+T_out+T1+T2+T6+T7+T8+hour+time_of_day)^2,atributes)
corr_data = as.data.frame(atributes_with_interactions)
corr_data$logAppliances = data$logAppliances
library(lubridate)
library(corrplot)
res <- cor(corr_data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
res = as.data.frame(res)
res[abs(res$logAppliances) > 0.4] # nie istnieja korelacje wieksze od 0.4,
atributes = scale(atributes)
boruta_atributes = as.data.frame(atributes)
boruta_atributes$logAppliances = data$logAppliances
boruta_atributes = as.data.frame(boruta_atributes)
str(boruta_atributes)
#install.packages("Boruta")
library(Boruta)
set.seed(42)
boruta.train <- Boruta(logAppliances~., data = boruta_atributes, doTrace = 2)
print(boruta.train)
final.train <- TentativeRoughFix(boruta.train)
print(final.train)
plot(final.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(final.train$ImpHistory),function(i)
final.train$ImpHistory[is.finite(final.train$ImpHistory[,i]),i])
names(lz) <- colnames(final.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(final.train$ImpHistory), cex.axis = 0.7)
write.csv(atributes, '../data/energy_data_after_processing.csv')
dt = sort(sample(nrow(atributes), nrow(atributes)*.8))
train<-data[dt,]
test<-data[-dt,]
write.csv(train, '../data/energy_data_train.csv')
write.csv(test, '../data/energy_data_test.csv')
train<-read.csv("../data/energy_data_train.csv")
train_y<-train$Appliances
train_x <- subset(train, select = -c(lights, Appliances) )
# w ilu kolumnach brakuje danych
which(is.na(train))
# ile jest łącznie brakujących danych
sum(is.na(train))
mising<-train[is.na(train),]
relation <- lm(Appliances~.,train)
train<-read.csv("../data/energy_data_train.csv")
train_y<-train$Appliances
train_x <- subset(train, select = -c(lights, Appliances, logAppliances) )
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights, Appliances) )
relation <- lm(logAppliances~.,train)
relation <- lm(logAppliances~.,train)
relation
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights, Appliances) )
model1 <- lm(logAppliances~.,train)
model1
test<-read.csv("../data/energy_data_test.csv")
test <- subset(test, select = -c(lights, Appliances) )
predict(model1, newdata = p)
test<-read.csv("../data/energy_data_test.csv")
test <- subset(test, select = -c(lights, Appliances) )
predict(model1, newdata = test)
model1 <- lm(logAppliances~.,train)
summary(model1)
model1 <- lm(logAppliances~.,train,na.action=na.omit)
summary(model1)
model1 <- lm(logAppliances~.,train,na.action=na.exclude)
summary(model1)
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
library(lubridate)
library(corrplot)
library(Hmisc)
data$logAppliances = log(data$Appliances)
#data$logVisibility = log(data$Visibility)
#data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)
res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
tl.col = "black")
atributes <- data[,!names(data) %in% c("date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances")]
str(atributes)
atributes_with_interactions = model.matrix(~(lights+Press_mm_hg+RH_1+RH_2+RH_6+RH_7+RH_8+RH_9+RH_out+T_out+T1+T2+T6+T7+T8+hour+time_of_day)^2,atributes)
corr_data = as.data.frame(atributes_with_interactions)
corr_data$logAppliances = data$logAppliances
library(lubridate)
library(corrplot)
res <- cor(corr_data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
res = as.data.frame(res)
res[abs(res$logAppliances) > 0.4] # nie istnieja korelacje wieksze od 0.4,
dt = sort(sample(nrow(atributes), nrow(atributes)*.8))
train<-atributes[dt,]
test<-atributes[-dt,]
write.csv(train, '../data/energy_data_train.csv')
write.csv(train, '../data/energy_data_train.csv')
write.csv(test, '../data/energy_data_test.csv')
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights, Appliances) )
dt = sort(sample(nrow(boruta_atributes), nrow(boruta_atributes)*.8))
train<-boruta_atributes[dt,]
test<-boruta_atributes[-dt,]
write.csv(train, '../data/energy_data_train.csv')
write.csv(test, '../data/energy_data_test.csv')
dt = sort(sample(nrow(boruta_atributes), nrow(boruta_atributes)*.8))
train<-boruta_atributes[dt,]
test<-boruta_atributes[-dt,]
write.csv(train, '../data/energy_data_train.csv')
write.csv(test, '../data/energy_data_test.csv')
train<-read.csv("../data/energy_data_train.csv")
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights, Appliances) )
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
model1 <- lm(logAppliances~.,train,na.action=na.exclude)
summary(model1)
test<-read.csv("../data/energy_data_test.csv")
test <- subset(test, select = -c(lights, Appliances) )
test<-read.csv("../data/energy_data_test.csv")
test <- subset(test, select = -c(lights) )
predict(model1, newdata = test)
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
prediction<-predict(model1, newdata = test_attributes)
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
prediction<-predict(model1, newdata = test_attributes)
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
prediction<-predict(model1, newdata = test_attributes)
rmse<-sqrt(mean((test_y - prediction)^2))
rmse
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
prediction<-predict(model1, newdata = test_attributes)
rmse<-sqrt(mean((test_y$logAppliances - prediction)^2))
rmse
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(test, select = -c(lights, logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
library(caret)
install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(test, select = -c(lights, logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
#install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(test, select = -c(lights, logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
train_attributes = predict(pre_proc_val, train_attributes)
test_attributes = predict(pre_proc_val, test_attributes)
#install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(test, select = -c(lights, logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
train_attributes = predict(pre_proc_val, train_attributes)
test_attributes = predict(pre_proc_val, test_attributes)
train <- cbind(test_attributes, train$logAppliances)
#install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(test, select = -c(lights, logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
train_attributes = predict(pre_proc_val, train_attributes)
test_attributes = predict(pre_proc_val, test_attributes)
train <- cbind(train_attributes, train$logAppliances)
#install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(lights, logAppliances) )
#install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
train_attributes = predict(pre_proc_val, train_attributes)
test_attributes = predict(pre_proc_val, test_attributes)
train <- cbind(train_attributes, train$logAppliances)
model1 <- lm(logAppliances~.,train,na.action=na.exclude)
#install.packages("caret")
library(caret)
train<-read.csv("../data/energy_data_train.csv")
train <- subset(train, select = -c(lights) )
train_attributes <- subset(train, select = -c(logAppliances) )
pre_proc_val <- preProcess(train_attributes, method = c("center", "scale"))
test<-read.csv("../data/energy_data_test.csv")
test_attributes <- subset(test, select = -c(lights, logAppliances) )
test_y <- subset(test, select = c( logAppliances) )
train_attributes = predict(pre_proc_val, train_attributes)
test_attributes = predict(pre_proc_val, test_attributes)
logAppliances<-train$logAppliances
train <- cbind(train_attributes, logAppliances)
model1 <- lm(logAppliances~.,train,na.action=na.exclude)
summary(model1)
prediction<-predict(model1, newdata = test_attributes)
rmse<-sqrt(mean((test_y$logAppliances - prediction)^2))
rmse
prediction<-predict(model1, newdata = test_attributes)
rmse<-sqrt(mean((test_y$logAppliances - prediction)^2))
rmse
#Step 1 - create the evaluation metrics function
eval_metrics = function(model, df, predictions, target){
resids = df[,target] - predictions
resids2 = resids**2
N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
#Step 1 - create the evaluation metrics function
eval_metrics = function(model, y, predictions){
resids = y - predictions
resids2 = resids**2
N = length(predictions)
r2 = as.character(round(summary(model)$r.squared, 2))
adj_r2 = as.character(round(summary(model)$adj.r.squared, 2))
print(adj_r2) #Adjusted R-squared
print(as.character(round(sqrt(sum(resids2)/N), 2))) #RMSE
}
# Step 2 - predicting and evaluating the model on train data
predictions = predict(model1, newdata = train_attributes)
eval_metrics(model1, train$logAppliances, predictions,)
# Step 2 - predicting and evaluating the model on train data
predictions = predict(model1, newdata = train_attributes)
eval_metrics(model1, train$logAppliances, predictions)
# Step 3 - predicting and evaluating the model on test data
predictions = predict(model1, newdata = test_attributes)
eval_metrics(model1, test_y, predictions)
chisq.test
chisq_T
#ZAD 1_a
month <- c(1,2,3,4,5,6,7,8,9,10,11,12)
suicide <-c(1867, 1789, 1944, 2094, 2097, 1981, 1887, 2024, 1928, 2032, 1978, 1859)
month_days <-c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
plot(month,suicide, type="l", xlab="Month", ylab="suicide number")
axis(1, at = month)
chisq_T<- chisq.test(suicide/sum(suicide), month_days/sum(month_days))
alfa=0.05
c=qchisq(1-alfa, 12)
chisq_T
#ZAD 1_a
month <- c(1,2,3,4,5,6,7,8,9,10,11,12)
suicide <-c(1867, 1789, 1944, 2094, 2097, 1981, 1887, 2024, 1928, 2032, 1978, 1859)
month_days <-c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
plot(month,suicide, type="l", xlab="Month", ylab="suicide number")
axis(1, at = month)
chisq_T<- chisq.test(suicide/sum(suicide), month_days/sum(month_days))
alfa=0.05
c=qchisq(1-alfa, 12-1)
chisq_T
if(chisq_T$statistic>c){
message("Sezonowy charakter")
}else{
message("Równomierny charakter")
}
#ZAD 1_a
month <- c(1,2,3,4,5,6,7,8,9,10,11,12)
suicide <-c(1867, 1789, 1944, 2094, 2097, 1981, 1887, 2024, 1928, 2032, 1978, 1859)
month_days <-c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
plot(month,suicide, type="l", xlab="Month", ylab="suicide number")
axis(1, at = month)
chisq_T<- chisq.test(suicide/sum(suicide), month_days/sum(month_days))
alfa=0.01
c=qchisq(1-alfa, 12-1)
chisq_T
if(chisq_T$statistic>c){
message("Sezonowy charakter")
}else{
message("Równomierny charakter")
}
#ZAD 1_a
month <- c(1,2,3,4,5,6,7,8,9,10,11,12)
suicide <-c(1867, 1789, 1944, 2094, 2097, 1981, 1887, 2024, 1928, 2032, 1978, 1859)
month_days <-c(31, 28, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31)
plot(month,suicide, type="l", xlab="Month", ylab="suicide number")
axis(1, at = month)
chisq_T<- chisq.test(suicide/sum(suicide), month_days/sum(month_days))
alfa=0.01
c=qchisq(1-alfa, 12-1)
chisq_T
if(chisq_T$statistic>c){
message("Sezonowy charakter")
}else{
message("Równomierny charakter")
}
s=vector()
for(i in 1:12){
s[i]=suicide[i]-sum(suicide)/sum(month_days)*month_days[i]
}
plot(month,s, type="l", xlab="Month", ylab="diffrence in suicide number")
axis(1, at = month)
#Zad 2_a
data <- read.delim("tempciala.txt", header = TRUE, sep = ",")
k<-data[data[,"p"]==2,]
m<-data[data[,"p"]==1,]
message("Kobiety temperatura wartość średnia: ", mean(k[,"temp"]), " , odchylenie standardowe: ", sd(k[,"temp"]))
message("Mężczyźni temparatura wartość średnia: ", mean(m[,"temp"]), " , odchylenie standardowe: ", sd(m[,"temp"]))
q = seq(0.01, 0.99, 0.05)
teor_val_m = rnorm(length(m[,"temp"]),mean = mean(m[,"temp"]) , sd = sqrt(sd(m[,"temp"])))
teor_quant_m = quantile(teor_val_m, q)
teor_quant_func_m = qnorm(q, mean = mean(m[,"temp"]), sd = sqrt(sd(m[,"temp"])))
ekper_quant_m=quantile(m[,"temp"], q)
qqplot(ekper_quant_m, teor_quant_func_m, xlab="Kwantyle", ylab="Kwantyle rozkladu norm")
points(teor_quant_m, teor_quant_func_m , col="red")
ekper_quant_reg<-lm(teor_quant_func_m~ekper_quant_m )
teor_quant_reg<-lm(teor_quant_func_m~teor_quant_m )
abline(ekper_quant_reg)
abline(teor_quant_reg,col="red")
title("Wykres kwantyl-kwantyl temperatury ciala mezczyzn")
legend("topleft", legend = c("dane","symulacja"), col = c("black", "red"), lwd=2)
teor_val_k = rnorm(length(k[,"temp"]),mean = mean(k[,"temp"]) , sd = sqrt(sd(k[,"temp"])))
teor_quant_k = quantile(teor_val_k, q)
teor_quant_func_k = qnorm(q, mean = mean(k[,"temp"]), sd = sqrt(sd(k[,"temp"])))
ekper_quant_k=quantile(k[,"temp"], q)
qqplot(ekper_quant_k, teor_quant_func_k, xlab="Kwantyle", ylab="Kwantyle rozkladu norm")
points(teor_quant_k, teor_quant_func_k , col="red")
ekper_quant_reg<-lm(teor_quant_func_k~ekper_quant_k )
teor_quant_reg<-lm(teor_quant_func_k~teor_quant_k )
abline(ekper_quant_reg)
abline(teor_quant_reg,col="red")
title("Wykres kwantyl-kwantyl temperatury ciala kobiet")
legend("topleft", legend = c("dane","symulacja"), col = c("black", "red"), lwd=2)
#Zad 2_b
#https://data-flair.training/blogs/hypothesis-testing-in-r/
t.test(k[,"temp"], mu = 36.6)
t
data <- read.delim("tempciala.txt", header = TRUE, sep = ",")
k<-data[data[,"p"]==2,]
m<-data[data[,"p"]==1,]
