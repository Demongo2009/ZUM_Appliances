
TYP DANYCH

Korzystamy z danych z poprzedniego etapu.

```{r}
data <- read.csv(file = "../data/energy_data_after_analysis.csv", stringsAsFactors = FALSE)
str(data)
```

WARTOŚCI BRAKUJĄCE

Uzupełniamy zerami ponieważ danych brakujacych jest tylko 6.

```{r}
# w ilu kolumnach brakuje danych
which(is.na(data))
# ile jest łącznie brakujących danych
sum(is.na(data))
mising<-data[is.na(data),]
data = na.omit(data)
#data[is.na(data)] = 0
```

Mozemy zauwazyc ze atrybuty Appliances, visibility, windspeed, rh_out, t_dewpoint, t9, t3, t4, t5 maja rozklady nie bedace rozkladem normalnym.

Atrybuty rv1, rv2, r6 wydaja sie byc atrybutami losowymi.

```{r}
library(lubridate)
library(corrplot)
library(Hmisc)

data$logAppliances = log(data$Appliances)
#data$logVisibility = log(data$Visibility)
#data$logWindspeed = log(data$Windspeed)
#data$logRh_out=log(data$Tdewpoint)
#data$logT9=log(data$T9)
#data$logT3=log(data$T3)
#data$logT4=log(data$T4)
#data$logT5=log(data$T5)

```

Dla nowo powstalych atrybutów zlogarytmowanych sprawdzamy korelacje z kolumna logAppliances.


```{r}

res <- cor(data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
corrplot(res, type = "full", order = "hclust",
         tl.col = "black")

```

Dokonujemy selekcji artybutów bazując na korelacji z logAppliances.
Odpadają następujące kolumny: "date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances".

```{r}


atributes <- data[,!names(data) %in% c("date", "logRh_out", "logWindspeed","X","T3","T4","T5","T9","Tdewpoint","rv1","rv2","RH_5","RH_3","RH_4","Windspeed","Visibility","logVisibility","Appliances","logAppliances")]
str(atributes)
```

Teraz bedziemy probowac znalezc dodatkowe atrybuty za pomoca tworzenia interakcji.

```{r}

atributes_with_interactions = model.matrix(~(lights+Press_mm_hg+RH_1+RH_2+RH_6+RH_7+RH_8+RH_9+RH_out+T_out+T1+T2+T6+T7+T8+hour+time_of_day)^2,atributes)
corr_data = as.data.frame(atributes_with_interactions)
corr_data$logAppliances = data$logAppliances
library(lubridate)
library(corrplot)
res <- cor(corr_data, use = "complete.obs")
res[is.na(res)] = 0
round(res, 2)
res = as.data.frame(res)
res[abs(res$logAppliances) > 0.4] # nie istnieja korelacje wieksze od 0.4,
```


Analiza korelacji interakcji wskazuje ze nie sa one bardziej wartosciowe od artybutów. Dlatego algorytm boruta wykonujemy na atrybutach bez interakcji.

```{r}
atributes = scale(atributes)
boruta_atributes = as.data.frame(atributes)
boruta_atributes$logAppliances = data$logAppliances
boruta_atributes = as.data.frame(boruta_atributes)
str(boruta_atributes)
#install.packages("Boruta")
library(Boruta)

set.seed(42)
boruta.train <- Boruta(logAppliances~., data = boruta_atributes, doTrace = 2)

print(boruta.train)

final.train <- TentativeRoughFix(boruta.train)
print(final.train)

plot(final.train, xlab = "", xaxt = "n")
lz<-lapply(1:ncol(final.train$ImpHistory),function(i)
final.train$ImpHistory[is.finite(final.train$ImpHistory[,i]),i])
names(lz) <- colnames(final.train$ImpHistory)
Labels <- sort(sapply(lz,median))
axis(side = 1,las=2,labels = names(Labels), at = 1:ncol(final.train$ImpHistory), cex.axis = 0.7)
```


```{r}
write.csv(atributes, '../data/energy_data_after_processing.csv')
```

Split into test and train data sets(80% - 20% split)

```{r}
dt = sort(sample(nrow(boruta_atributes), nrow(boruta_atributes)*.8))
train<-boruta_atributes[dt,]
test<-boruta_atributes[-dt,]
```

save test and train

```{r}
write.csv(train, '../data/energy_data_train.csv')
write.csv(test, '../data/energy_data_test.csv')
```

